# Taskin Face Tracking

Sistema de detecÃ§Ã£o facial em tempo real integrado ao mascote Taskin usando MediaPipe Face Landmarker.

## ğŸ¯ Funcionalidades

### DetecÃ§Ã£o Facial

- **478 Pontos Faciais (Landmarks)**: Mapeamento completo da geometria facial
- **52 Blendshapes**: Coeficientes de expressÃµes faciais (ARKit compatible)
- **DetecÃ§Ã£o em Tempo Real**: Via webcam com baixa latÃªncia
- **Processamento Local**: Roda no navegador usando WebAssembly + GPU

### SincronizaÃ§Ãµes DisponÃ­veis

1. **ğŸ‘€ SincronizaÃ§Ã£o de Olhos**
   - Os olhos do Taskin seguem a direÃ§Ã£o do seu olhar
   - Detecta: olhar para cima/baixo/esquerda/direita
   - Detecta: piscadas e olhos arregalados

2. **ğŸ‘„ SincronizaÃ§Ã£o de Boca**
   - A boca do Taskin abre conforme vocÃª abre a sua
   - Detecta grau de abertura em tempo real

3. **ğŸ˜Š SincronizaÃ§Ã£o de ExpressÃµes**
   - O mood do Taskin muda baseado em suas expressÃµes:
     - **Sorriso** â†’ `happy`
     - **Franzir** â†’ `annoyed`
     - **Olhos arregalados** â†’ `furious`
     - **Boca aberta** â†’ `sarcastic`
     - **Neutro** â†’ `neutral`

## ğŸš€ Como Usar

### Componente Completo (Recomendado)

```vue
<template>
  <TaskinWithFaceTracking
    :mascot-size="300"
    :show-webcam="true"
    :show-debug="false"
  />
</template>

<script setup>
import { TaskinWithFaceTracking } from '@opentask/taskin-design-vue';
</script>
```

### Composable (Customizado)

```vue
<template>
  <div>
    <video ref="videoRef" autoplay playsinline />
    <button @click="startDetection">Iniciar</button>

    <TaskinComposed
      :mood="currentMood"
      :eye-tracking-mode="'custom'"
      :eye-custom-position="eyePosition"
    />
  </div>
</template>

<script setup>
import { ref, watch } from 'vue';
import { useFaceLandmarker, TaskinComposed } from '@opentask/taskin-design-vue';

const videoRef = ref(null);
const currentMood = ref('neutral');
const eyePosition = ref({ x: 0, y: 0 });

const faceLandmarker = useFaceLandmarker(videoRef, {
  enableBlendshapes: true,
  minDetectionConfidence: 0.5,
});

const startDetection = () => {
  faceLandmarker.startDetection();
};

// Sincroniza direÃ§Ã£o dos olhos
watch(
  () => faceLandmarker.state.value.blendShapes,
  (blendShapes) => {
    if (!blendShapes) return;

    const eyeLook = faceLandmarker.getEyeLookDirection();
    eyePosition.value = { x: eyeLook.x, y: eyeLook.y };

    // Atualiza mood baseado em expressÃµes
    const smile = faceLandmarker.getSmileIntensity();
    currentMood.value = smile > 0.6 ? 'happy' : 'neutral';
  },
);
</script>
```

## ğŸ“Š API do Composable

### `useFaceLandmarker(videoElement, options)`

#### ParÃ¢metros

```typescript
interface UseFaceLandmarkerOptions {
  enableBlendshapes?: boolean; // PadrÃ£o: true
  minDetectionConfidence?: number; // PadrÃ£o: 0.5 (0.0 - 1.0)
  minTrackingConfidence?: number; // PadrÃ£o: 0.5 (0.0 - 1.0)
  onDetection?: (result) => void; // Callback opcional
}
```

#### Retorno

```typescript
{
  state: Ref<FaceLandmarkerState>,     // Estado reativo da detecÃ§Ã£o
  startDetection: () => Promise<void>, // Inicia webcam e detecÃ§Ã£o
  stopDetection: () => void,           // Para detecÃ§Ã£o e webcam

  // Helpers para extrair informaÃ§Ãµes
  getEyeLookDirection: () => { x: number, y: number },
  getEyeOpenness: () => { left: number, right: number },
  isEyesWide: () => boolean,
  getMouthOpenness: () => number,
  getSmileIntensity: () => number,
  getFrownIntensity: () => number,
}
```

### Estado da DetecÃ§Ã£o

```typescript
interface FaceLandmarkerState {
  isReady: boolean; // MediaPipe carregado
  isDetecting: boolean; // Webcam ativa e detectando
  error: string | null; // Mensagem de erro se houver
  blendShapes: FaceLandmarkerBlendShapes | null; // 52 coeficientes
  landmarks: Array<{ x; y; z }> | null; // 478 pontos faciais
}
```

### Blendshapes Principais

```typescript
interface FaceLandmarkerBlendShapes {
  // Olhos
  eyeBlinkLeft: number; // 0 = aberto, 1 = fechado
  eyeBlinkRight: number;
  eyeLookUpLeft: number; // Olhar para cima
  eyeLookDownLeft: number; // Olhar para baixo
  eyeLookInLeft: number; // Olhar para dentro
  eyeLookOutLeft: number; // Olhar para fora
  eyeWideLeft: number; // Olhos arregalados
  eyeSquintLeft: number; // Olhos semicerrados

  // Boca
  jawOpen: number; // 0 = fechada, 1 = totalmente aberta
  mouthSmileLeft: number; // Intensidade do sorriso
  mouthSmileRight: number;
  mouthFrownLeft: number; // Franzir
  mouthFrownRight: number;
  mouthPucker: number; // Bico

  // ... 52 blendshapes no total
}
```

## ğŸ® Props do TaskinProps

Novas propriedades adicionadas para suportar face tracking:

```typescript
interface TaskinProps {
  // ... props existentes

  enableFaceLandmarker?: boolean; // Ativa detecÃ§Ã£o facial
  syncMouth?: boolean; // Sincroniza boca
  syncEyes?: boolean; // Sincroniza olhos
  syncExpressions?: boolean; // Sincroniza expressÃµes/mood
}
```

## ğŸ”§ Requisitos TÃ©cnicos

### Navegador

- Chrome/Edge 90+
- Firefox 88+
- Safari 14.1+
- Suporte a WebRTC (getUserMedia)
- Suporte a WebAssembly

### PermissÃµes

- Acesso Ã  webcam (solicitado ao usuÃ¡rio)
- ConexÃ£o com internet (para baixar modelo ~10MB na primeira vez)

### Performance

- **CPU**: Dual-core 2.0 GHz+ recomendado
- **GPU**: Acelera processamento se disponÃ­vel (via WebGL)
- **FPS**: 30-60 fps dependendo do hardware
- **LatÃªncia**: < 50ms tÃ­pico

## ğŸ“¦ DependÃªncias

```json
{
  "@mediapipe/tasks-vision": "latest" // Carregado via CDN
}
```

O MediaPipe Ã© carregado dinamicamente via CDN quando `startDetection()` Ã© chamado.
NÃ£o hÃ¡ necessidade de instalar manualmente.

## ğŸ¯ Exemplos de Uso

### Exemplo 1: Avatar Interativo

```vue
<TaskinWithFaceTracking :mascot-size="400" :show-webcam="false" />
```

### Exemplo 2: Video Conference

```vue
<div style="display: flex; gap: 20px;">
  <video ref="localVideo" autoplay />
  <TaskinComposed
    :eye-tracking-mode="'custom'"
    :eye-custom-position="eyePosition"
    :mood="detectedMood"
  />
</div>
```

### Exemplo 3: Jogo Interativo

```vue
<script setup>
const faceLandmarker = useFaceLandmarker(videoRef);

watch(
  () => faceLandmarker.getMouthOpenness(),
  (openness) => {
    if (openness > 0.7) {
      // Jogador "gritou" - ativa power-up
      activatePowerUp();
    }
  },
);

watch(
  () => faceLandmarker.isEyesWide(),
  (isWide) => {
    if (isWide) {
      // Jogador estÃ¡ surpreso
      showSurpriseEffect();
    }
  },
);
</script>
```

## ğŸ› Troubleshooting

### Erro: "Webcam nÃ£o acessÃ­vel"

- Verifique permissÃµes do navegador
- Tente usar HTTPS (getUserMedia requer contexto seguro)
- Verifique se outra aplicaÃ§Ã£o estÃ¡ usando a webcam

### Erro: "Falha ao carregar MediaPipe"

- Verifique conexÃ£o com internet
- Verifique se CDN estÃ¡ acessÃ­vel
- Tente limpar cache do navegador

### Performance Baixa

- Reduza resoluÃ§Ã£o da webcam
- Desative GPU acceleration se houver problemas
- Use `minDetectionConfidence` mais alto (0.7)

## ğŸ“š Recursos

- [MediaPipe Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker)
- [ARKit Blend Shapes](https://developer.apple.com/documentation/arkit/arfaceanchor/blendshapelocation)
- [WebRTC getUserMedia](https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia)

## ğŸ¨ Storybook

Veja exemplos interativos no Storybook:

```bash
pnpm storybook
```

Navegue para: **Organisms > Taskin > Face Tracking**

## ğŸ“ LicenÃ§a

Este componente faz parte do `@opentask/taskin-design-vue` e segue a mesma licenÃ§a do pacote principal.
